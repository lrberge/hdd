<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>hdd walkthrough • hdd</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="hdd walkthrough">
<meta property="og:description" content="hdd">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hdd</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/hdd_walkthrough.html">hdd walkthrough</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>hdd walkthrough</h1>
                        <h4 data-toc-skip class="author">Laurent
Bergé</h4>
            
            <h4 data-toc-skip class="date">2023-08-22</h4>
      
      
      <div class="hidden name"><code>hdd_walkthrough.Rmd</code></div>

    </div>

    
    
<!-- output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: false -->
<!-- fontsize: 12pt
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true -->
<pre><code><span><span class="co">#&gt; This vignette takes the example of a data set of over 13GB on disk, and thus cannot be run non-locally.</span></span></code></pre>
<p><code>hdd</code> provides a class of data, <em>hard drive data</em>,
allowing the easy importation/manipulation of out of memory data sets.
The data sets are located on disk but look like in-memory, the syntax
for manipulation is similar to <a href="https://github.com/Rdatatable/data.table/wiki" class="external-link">data.table</a>.
Operations are performed “chunk-wise” behind the scene. Here is a brief
presentation of the main features.</p>
<div class="section level2">
<h2 id="example-with-publication-data">Example with publication data<a class="anchor" aria-label="anchor" href="#example-with-publication-data"></a>
</h2>
<p>Throughout this document, we will use the example of the Microsoft
Academic Graph data (<a href="https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/" class="external-link uri">https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/</a>).
This large and freely available data set contains all scientific
publications meta information (like authors, titles, institutions, etc…)
as collected by Microsoft and used in <a href="https://aka.ms/microsoft-academic" class="external-link">microsoft academic</a>.</p>
<p>The data is in the form of a relational data base of usually large
text files (well over 10GB). We’ll see how to deal with them in
<code>R</code> with <code>hdd</code>.</p>
<div class="section level3">
<h3 id="importation">Importation<a class="anchor" aria-label="anchor" href="#importation"></a>
</h3>
<p>First we have to import the data into <code>R</code> through a
<code>hdd</code> data set. We’re interested in importing the information
on authors. We’ll use the <code>txt2hdd</code> function. But first let’s
have a look at the data.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">hdd</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/peek.html">peek</a></span><span class="op">(</span><span class="st">"_path/authors.txt"</span><span class="op">)</span></span></code></pre></div>
<p>We can see that the data set contains 8 variables, some are text,
other are numeric. By default, the function <code>peek</code> also
displays the delimiter of the data, here it is a tab delimited text
file.</p>
<p>Now let’s import the data. From the documentation, we can retrieve
the variable names, and we will use them:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">col_names</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"AuthorId"</span>, <span class="st">"Rank"</span>, <span class="st">"NormalizedName"</span>, <span class="st">"DisplayName"</span>, </span>
<span>              <span class="st">"LastKnownAffiliationId"</span>, </span>
<span>              <span class="st">"PaperCount"</span>, <span class="st">"CitationCount"</span>, <span class="st">"CreatedDate"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/txt2hdd.html">txt2hdd</a></span><span class="op">(</span><span class="st">"_path/authors.txt"</span>, <span class="co"># The text file</span></span>
<span>        <span class="co"># dirDest: The destination of the HDD data =&gt; must be a directory</span></span>
<span>        dirDest <span class="op">=</span> <span class="st">"_path/hdd_authors"</span>, </span>
<span>        chunkMB <span class="op">=</span> <span class="fl">500</span>, col_names <span class="op">=</span> <span class="va">col_names</span><span class="op">)</span></span></code></pre></div>
<p>By default, the types of the variables are automatically set, based
on the guess of the function <code>fread</code> from package
<code>data.table</code>. Note that 64bits integers variables are
imported as doubles. You can set the column types yourself using the
function <code>cols</code> or <code>cols_only</code> from package
<code>readr</code>. In any case, if there are importing problems, a
specific repository, which is itself a hdd file, reporting all importing
problems is created (in the example, it there were problems, it would be
located at <code>"_path/hdd_authors/problems"</code>).</p>
<p>The function <code>txt2hdd</code> creates a folder on disk containing
the full data set divided into several files named
<code>slice_XX.fst</code> with XX its number. The <code>.fst</code>
files are in a format for fast reading/writing on disk (see
<code>fst</code> <a href="http://www.fstpackage.org/" class="external-link">homepage</a>).
Every time a <code>hdd</code> data set is created, the associated folder
on disk includes a file <code>_hdd.txt</code> containing: i) a summary
of the data (number of rows/columns, first five observations) and ii)
the log of the commands which created it.</p>
<p>Now that the data is imported into a <code>hdd</code> file, let’s
have a look at it:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">authors</span> <span class="op">=</span> <span class="fu"><a href="../reference/hdd.html">hdd</a></span><span class="op">(</span><span class="st">"_path/hdd_authors"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">authors</span><span class="op">)</span></span></code></pre></div>
<p>The summary provides some general information: the location of the
data in the hard drive (note that this is the location on my hard
drive!), the size of the data set on disk (which is lower that what it
would be in-memory due to compression), here 13GB, the number of chunks,
here 69, the number of lines, here 217 millions, and the numer of
variables.</p>
<p>Now let’s have a quick look at the first lines of the data:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">authors</span><span class="op">)</span></span></code></pre></div>
<p>It’s indeed the same data as in the text file. You can see that you
can access it as a regular data frame.</p>
<div class="section level4">
<h4 id="importing-with-preprocessing">Importing with preprocessing<a class="anchor" aria-label="anchor" href="#importing-with-preprocessing"></a>
</h4>
<p>Now assume that you do not want to import the full text file because
some information might be unecessary to you – or you may want to
generate new information straight away. You can apply a preprocessing
function while importing. Assume we want to import only the first three
columns for which the names, in variable <code>NormalizedName</code>,
contain only ASCII characters. We could do as follows:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">fun_ascii</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="co"># selection of the first 3 columns</span></span>
<span>    <span class="va">res</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span>    <span class="co"># selection of only ascii names</span></span>
<span>    <span class="va">res</span><span class="op">[</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/iconv.html" class="external-link">iconv</a></span><span class="op">(</span><span class="va">NormalizedName</span>, to <span class="op">=</span> <span class="st">"ASCII"</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">col_names</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"AuthorId"</span>, <span class="st">"Rank"</span>, <span class="st">"NormalizedName"</span>, <span class="st">"DisplayName"</span>, </span>
<span>              <span class="st">"LastKnownAffiliationId"</span>, </span>
<span>              <span class="st">"PaperCount"</span>, <span class="st">"CitationCount"</span>, <span class="st">"CreatedDate"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/txt2hdd.html">txt2hdd</a></span><span class="op">(</span><span class="st">"_path/authors.txt"</span>, dirDest <span class="op">=</span> <span class="st">"_path/hdd_authors_ascii"</span>, </span>
<span>        chunkMB <span class="op">=</span> <span class="fl">500</span>, col_names <span class="op">=</span> <span class="va">col_names</span>,</span>
<span>        preprocessfun <span class="op">=</span> <span class="va">fun_ascii</span><span class="op">)</span></span></code></pre></div>
<p>Let’s look at the new data set:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">authors_ascii</span> <span class="op">=</span> <span class="fu"><a href="../reference/hdd.html">hdd</a></span><span class="op">(</span><span class="st">"_path/hdd_authors_ascii"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">authors_ascii</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="manipulation">Manipulation<a class="anchor" aria-label="anchor" href="#manipulation"></a>
</h3>
<p>You can manipulate the data as with any other
<code>data.table</code>, but the extraction method for <code>hdd</code>
objects (<code>[.hdd</code>) includes a few extra arguments.</p>
<p>By default, the results are put into memory. Using the previous
<code>author</code> data, let’s find out all the author names containing
the word “Einstein”:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">names_einstein</span> <span class="op">=</span> <span class="va">authors</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">grepl</a></span><span class="op">(</span><span class="st">"\\beinstein\\b"</span>, <span class="va">NormalizedName</span><span class="op">)</span>, </span>
<span>                         <span class="va">NormalizedName</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">names_einstein</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">names_einstein</span><span class="op">)</span></span></code></pre></div>
<p>That’s it, the algorithm has gone through the 217 million rows and
found 1700 author names containing “Einstein”. You can see that the
command is the same as for a regular <code>data.table</code>.</p>
<p>But what if the result of the query does not fit into memory? You can
still perform the query by adding the argument <code>newfile</code>. Now
the result will be a <code>hdd</code> data set located in the path
provided by the argument <code>newfile</code>. As in the
<code>"Importing with preprocessing"</code> section, let’s create the
data set containing the first three columns and dropping all names with
non-ASCII characters. We can do as follows:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">authors</span><span class="op">[</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/iconv.html" class="external-link">iconv</a></span><span class="op">(</span><span class="va">NormalizedName</span>, to <span class="op">=</span> <span class="st">"ASCII"</span><span class="op">)</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>        newfile <span class="op">=</span> <span class="st">"_path/hdd_authors_ascii"</span><span class="op">]</span></span></code></pre></div>
<p>The result is a new <code>hdd</code> data set located in
<code>"_path/hdd_authors_ascii"</code>, which can be of any size.</p>
</div>
<div class="section level3">
<h3 id="exploring-a-hdd-data-set">Exploring a hdd data set<a class="anchor" aria-label="anchor" href="#exploring-a-hdd-data-set"></a>
</h3>
<p>A <code>hdd</code> data set is made of several chunks, or files. You
can explore each of them individually using the argument
<code>file</code>. Further, you can use the special variable
<code>.N</code> to refer to the total number of files making the data
set. For example, let’s select the first name of each chunk (or
file):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">names_first</span> <span class="op">=</span> <span class="va">authors</span><span class="op">[</span><span class="fl">1</span>, <span class="va">NormalizedName</span>, file <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">.N</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">names_first</span><span class="op">)</span></span></code></pre></div>
<p>When you use the argument <code>file</code>, you can also use the
special variable <code>.N</code> in the index. Here by selecting the
last lines of each file:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">names_last</span> <span class="op">=</span> <span class="va">authors</span><span class="op">[</span><span class="va">.N</span>, <span class="va">NormalizedName</span>, file <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">.N</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">names_last</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="extracting-a-full-variable">Extracting a full variable<a class="anchor" aria-label="anchor" href="#extracting-a-full-variable"></a>
</h3>
<p>Of course you can extract a full variable with <code>$</code>, but
the algorithm will proceed only if the expected size is not too large.
For example the following code will raise an error because the expected
size of the variable, 7GB, is deemed too large:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">author_id</span> <span class="op">=</span> <span class="va">authors</span><span class="op">$</span><span class="va">AuthorId</span></span></code></pre></div>
<p>By default the cap at which this error is raised is 1GB. To drop the
cap, just set <code>setHdd_extract.cap(Inf)</code>, but then beware of
memory issues!</p>
</div>
<div class="section level3">
<h3 id="reading-full-hdd-data-sets-from-disk-to-memory">Reading full hdd data sets from disk to memory<a class="anchor" aria-label="anchor" href="#reading-full-hdd-data-sets-from-disk-to-memory"></a>
</h3>
<p>Use the function <code>readfst</code> to read <code>hdd</code> files
located on disk to memory. Of course the <code>hdd</code> file should be
<em>small</em> enough to fit in memory. An error will be raised if the
expected size of the data exceeds the value of
<code>getHdd_extract.cap(new_cap)</code> (default is 1GB), which you can
set with <code>setHdd_extract.cap(new_cap)</code>. For example:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># to read the full data set into memory:</span></span>
<span><span class="va">base_authors</span> <span class="op">=</span> <span class="fu"><a href="../reference/readfst.html">readfst</a></span><span class="op">(</span><span class="st">"_path/hdd_authors"</span><span class="op">)</span></span>
<span><span class="co"># Alternative way</span></span>
<span><span class="va">authors_hdd</span> <span class="op">=</span> <span class="fu"><a href="../reference/hdd.html">hdd</a></span><span class="op">(</span><span class="st">"_path/hdd_authors"</span><span class="op">)</span></span>
<span><span class="va">base_authors</span> <span class="op">=</span> <span class="va">authors_hdd</span><span class="op">[</span><span class="op">]</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="slicing">Slicing<a class="anchor" aria-label="anchor" href="#slicing"></a>
</h2>
<p>Imagine you dispose of an in-memory data set to which you want to
apply some function – say for instance that you will have to apply a
cartesian merge. However the result of this function does not fit in
memomy. The function <code>hdd_slice</code> deals with it: it applies
the function to slices of the original data, and save the results in a
<code>hdd</code> data set. You’ll be then able to deal with the result
with <code>hdd</code>.</p>
<p>Let’s have an example with a cartesian merge:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># x: the original data set</span></span>
<span><span class="co"># y: the data set you want to merge to x</span></span>
<span><span class="va">cartesian_merge</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/merge.html" class="external-link">merge</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, allow.cartesian <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="../reference/hdd_slice.html">hdd_slice</a></span><span class="op">(</span><span class="va">x</span>, fun <span class="op">=</span> <span class="va">cartesian_merge</span>, </span>
<span>          dir <span class="op">=</span> <span class="st">"_path/result_merge"</span>, chunkMB <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<p>Here the data <code>x</code> will be split in 100MB chunks and the
function <code>cartesian_merge</code> will be applied to each of these
chunks. The results will be saved in a <code>hdd</code> data set located
in <code>_path/result_merge</code>. You’ll then be able to manipulate
the data in <code>_path/result_merge</code> as a regular
<code>hdd</code> data set.</p>
<p>This example involved a merging operation only, but you can apply any
kind of function (for example <code>x</code> can be a vector of text and
the function can be the creation of ngrams, etc…).</p>
</div>
<div class="section level2">
<h2 id="speed-considerations-and-limitations">Speed considerations and limitations<a class="anchor" aria-label="anchor" href="#speed-considerations-and-limitations"></a>
</h2>
<div class="section level3">
<h3 id="in-memory-operations-will-always-be-faster">In-memory operations will always be faster<a class="anchor" aria-label="anchor" href="#in-memory-operations-will-always-be-faster"></a>
</h3>
<p>Manipulating in-memory data will always be orders of mmagnitude
faster than manipulating on-disk data. This comes from the simple fact
that read/write operations on disk are about 100 times slower than
read/write in RAM – further the read and write on disk also involves
compression/decompression incurring increased CPU use. This is however
the only way to deal with very large data sets (except of course if you
have very deep pockets allowing you to have big RAM computers!).</p>
<p>This means that at the moment your final data set reaches a
memory-workable size, stop using <code>hdd</code> and start using
regular <code>R</code>. Package <code>hdd</code> exists to make the
transition from too-large-a-data-set to a memory-workable-data-set and
is not intended to be a tool for regular data manipulation.</p>
</div>
<div class="section level3">
<h3 id="on-aggregation">On aggregation<a class="anchor" aria-label="anchor" href="#on-aggregation"></a>
</h3>
<p>Since <code>hdd</code> data sets are split into multiple files, the
user cannot perform aggregate operations on some variable (i.e. using
the <code>by</code> clause in <code>data.table</code> language) and
obtain “valid” results. Indeed, the aggregate operations will be
performed chunk per chunk and <strong>not</strong> on the entirety of
the data set (which is not possible because of the size).</p>
<p>To circumvent this issue, the data set must be sorted by the
variable(s) on which aggregation is done – in which case the chunk by
chunk operations will be valid. To sort <code>hdd</code> data sets, the
function <code>hdd_setkey</code> has been created – in particular it
ensures that the keys do not spill across multiple files (to ensure
consistency of the chunk by chunk aggregation). But beware, it is
extremely slow (it involves multiple on-disk copying of the
<em>full</em> data set).</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>On the Microsoft Academic Graph data:</p>
<p>Arnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Darrin Eide, Bo-June
(Paul) Hsu, and Kuansan Wang. 2015. An Overview of Microsoft Academic
Service (MAS) and Applications. In Proceedings of the 24th International
Conference on World Wide Web (WWW 15 Companion). ACM, New York, NY, USA,
243-246. DOI=<a href="http://dx.doi.org/10.1145/2740908.2742839" class="external-link uri">http://dx.doi.org/10.1145/2740908.2742839</a></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Laurent Berge.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
